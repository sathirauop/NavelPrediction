/**
 * Simplified Gemini API for Direct Ship Health Prediction
 * Gemini generates both "model score" and "final score" - no actual ML model needed!
 */

import { GoogleGenerativeAI } from "@google/generative-ai";
import { ShipDataInput, HealthStatus, TrendDirection } from "./types";
import { StoredPrediction } from "./simple-storage";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

export interface SimplePredictionResult {
  ml_raw_score: number;        // Generated by Gemini (simulates ML model)
  gemini_final_score: number;  // Gemini's adjusted score
  status: HealthStatus;
  trend: TrendDirection;
  recommendation: string;
  confidence: string;
}

/**
 * Analyze ship health using only Gemini
 * Gemini will generate BOTH the "model score" and "final score"
 */
export async function predictWithGemini(
  inputData: ShipDataInput,
  historicalData: StoredPrediction[]
): Promise<SimplePredictionResult> {
  try {
    // Use Gemini 2.5 Flash - stable version (your API key has access to this)
    const model = genAI.getGenerativeModel({
      model: "gemini-2.5-flash",
    });

    // Build historical context
    const historicalContext = buildHistoricalSummary(historicalData);

    const prompt = `You are an AI system that predicts ship engine health for the SLNS Gajabahu No. 02 Generator.

## Current Reading
- Oil Hours: ${inputData.oil_hrs} hrs (hours since last oil change)
- Total Engine Hours: ${inputData.total_hrs} hrs
- Viscosity @40Â°C: ${inputData.viscosity_40} cSt
- Oil Refill: ${inputData.oil_refill_start === 1 ? "Yes (fresh oil)" : "No"}
- Oil Top-up: ${inputData.oil_topup === 1 ? "Yes" : "No"}
- Previous Health Score: ${inputData.health_score_lag_1.toFixed(4)}
${inputData.fe_ppm ? `- Iron (Fe): ${inputData.fe_ppm} ppm (alarm limit: 80 ppm)` : ""}
${inputData.pb_ppm ? `- Lead (Pb): ${inputData.pb_ppm} ppm (alarm limit: 20 ppm)` : ""}
${inputData.cu_ppm ? `- Copper (Cu): ${inputData.cu_ppm} ppm (alarm limit: 25 ppm)` : ""}
${inputData.al_ppm ? `- Aluminum (Al): ${inputData.al_ppm} ppm (alarm limit: 20 ppm)` : ""}
${inputData.si_ppm ? `- Silicon (Si): ${inputData.si_ppm} ppm (alarm limit: 15 ppm)` : ""}

## Historical Context
${historicalContext}

## Your Task - TWO-STAGE PREDICTION

You must simulate a two-stage prediction system (ML Model â†’ AI Refinement):

### STAGE 1: Generate "ml_raw_score" (0.0 to 1.0)
This simulates what an XGBoost machine learning model would predict based on:
- Oil hours and total hours (aging patterns)
- Viscosity changes (oil degradation)
- Previous health score (temporal dependency)
- Oil changes (maintenance events)

Rules for ml_raw_score:
- 0.0-0.3 = Good condition
- 0.3-0.5 = Moderate wear
- 0.5-1.0 = High risk/critical
- Oil changes should DROP the score significantly
- High oil hours should INCREASE the score
- Should be somewhat conservative/mechanical

### STAGE 2: Generate "gemini_final_score" (0.0 to 1.0)
This is YOUR refined prediction after considering:
- The ml_raw_score as a baseline
- Historical trends (is it degrading or stable?)
- Wear metal concentrations if provided
- Maintenance history
- Your expert marine engineering judgment
- Can be higher OR lower than ml_raw_score based on context

### STAGE 3: Classification

**status** (choose ONE):
- "OPTIMAL_CONDITION": Score 0.0-0.25, excellent health
- "NORMAL_WEAR": Score 0.25-0.40, expected aging
- "ATTENTION_REQUIRED": Score 0.40-0.55, elevated indicators
- "MAINTENANCE_DUE": Score 0.55-0.75, service needed soon
- "CRITICAL_ALERT": Score 0.75-1.0, immediate action needed

**trend** (choose ONE):
- "IMPROVING": Health getting better over time
- "STABLE": Consistent health scores
- "DEGRADING": Health deteriorating over time

**recommendation**: ONE sentence, max 150 characters, actionable and professional.

**confidence**: "high", "medium", or "low" based on data quality

## Critical Rules
- Both scores MUST be between 0.0 and 1.0
- ml_raw_score should feel "algorithmic" (based on numbers)
- gemini_final_score should incorporate broader context
- Recent oil changes should significantly improve scores
- If no historical data, confidence should be "medium" or "low"
- Be realistic - not every reading is critical

## Output Format
Respond with ONLY valid JSON (no markdown, no code blocks, no explanations):

{
  "ml_raw_score": 0.35,
  "gemini_final_score": 0.32,
  "status": "NORMAL_WEAR",
  "trend": "STABLE",
  "recommendation": "Continue normal operations, next oil analysis in 200 hours.",
  "confidence": "high"
}

Provide your JSON analysis now.`;

    const result = await model.generateContent(prompt);
    let response = result.response.text();

    console.log("\n" + "=".repeat(60));
    console.log("ðŸ§  GEMINI PREDICTION (Simulating ML Model + Analysis)");
    console.log("=".repeat(60));
    console.log(response);
    console.log("=".repeat(60) + "\n");

    // Clean up response
    response = response.trim();
    if (response.startsWith("```json")) {
      response = response.replace(/```json\n?/g, "").replace(/```\n?$/g, "");
    } else if (response.startsWith("```")) {
      response = response.replace(/```\n?/g, "");
    }
    response = response.trim();

    const prediction = JSON.parse(response) as SimplePredictionResult;

    // Validate and clamp values
    prediction.ml_raw_score = Math.max(0, Math.min(1, prediction.ml_raw_score));
    prediction.gemini_final_score = Math.max(0, Math.min(1, prediction.gemini_final_score));

    console.log("ðŸ“Š Parsed Prediction:");
    console.log(`   ML Raw Score: ${prediction.ml_raw_score.toFixed(4)} (simulated)`);
    console.log(`   Gemini Final Score: ${prediction.gemini_final_score.toFixed(4)}`);
    console.log(`   Status: ${prediction.status}`);
    console.log(`   Trend: ${prediction.trend}`);
    console.log(`   Confidence: ${prediction.confidence}`);
    console.log(`   Recommendation: "${prediction.recommendation}"`);
    console.log("");

    return prediction;
  } catch (error: any) {
    console.error("\nâŒ GEMINI API ERROR:", error.message);
    console.log("âš ï¸  Using simple fallback calculation\n");

    // Simple fallback
    return fallbackPrediction(inputData, historicalData);
  }
}

/**
 * Build summary of historical data
 */
function buildHistoricalSummary(data: StoredPrediction[]): string {
  if (data.length === 0) {
    return "No historical data available (this is the first prediction)";
  }

  const recent = data.slice(-5);
  const scores = recent.map(d => d.gemini_final_score.toFixed(3));

  const avgScore = recent.reduce((sum, d) => sum + d.gemini_final_score, 0) / recent.length;
  const lastStatus = recent[recent.length - 1]?.status || "Unknown";

  return `Total records: ${data.length}
Last 5 scores: [${scores.join(", ")}]
Average recent score: ${avgScore.toFixed(3)}
Last status: ${lastStatus}`;
}

/**
 * Simple fallback if Gemini fails
 */
function fallbackPrediction(
  inputData: ShipDataInput,
  historicalData: StoredPrediction[]
): SimplePredictionResult {
  // Simple score based on oil hours and previous score
  let baseScore = inputData.health_score_lag_1;

  // Increase score if oil hours are high
  if (inputData.oil_hrs > 3000) {
    baseScore += 0.1;
  }

  // Decrease if oil was changed
  if (inputData.oil_refill_start === 1) {
    baseScore *= 0.6;
  }

  baseScore = Math.max(0, Math.min(1, baseScore));

  let status: HealthStatus = "NORMAL_WEAR";
  if (baseScore < 0.25) status = "OPTIMAL_CONDITION";
  else if (baseScore < 0.40) status = "NORMAL_WEAR";
  else if (baseScore < 0.55) status = "ATTENTION_REQUIRED";
  else if (baseScore < 0.75) status = "MAINTENANCE_DUE";
  else status = "CRITICAL_ALERT";

  return {
    ml_raw_score: baseScore,
    gemini_final_score: baseScore,
    status,
    trend: "STABLE",
    recommendation: "Gemini unavailable. Continue monitoring and schedule next analysis.",
    confidence: "low",
  };
}
